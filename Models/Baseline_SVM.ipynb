{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import collections\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_curve\n",
    "from sklearn.metrics import hamming_loss, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imblearn in /home/sukku/anaconda3/lib/python3.7/site-packages (0.0)\n",
      "Requirement already satisfied: imbalanced-learn in /home/sukku/anaconda3/lib/python3.7/site-packages (from imblearn) (0.6.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/sukku/anaconda3/lib/python3.7/site-packages (from imbalanced-learn->imblearn) (0.14.0)\n",
      "Requirement already satisfied: scipy>=0.17 in /home/sukku/anaconda3/lib/python3.7/site-packages (from imbalanced-learn->imblearn) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.11 in /home/sukku/anaconda3/lib/python3.7/site-packages (from imbalanced-learn->imblearn) (1.18.1)\n",
      "Requirement already satisfied: scikit-learn>=0.22 in /home/sukku/anaconda3/lib/python3.7/site-packages (from imbalanced-learn->imblearn) (0.22.2.post1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "!pip install imblearn\n",
    "from imblearn.over_sampling import RandomOverSampler,SMOTE, ADASYN, SMOTENC, SVMSMOTE\n",
    "from imblearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data=pd.read_csv(\"/content/drive/My Drive/data/questions.csv\",usecols=[3,5,6]) \n",
    "data=pd.read_csv(\"codechef_questions_v6.csv\",usecols=[3,5,6]) \n",
    "# data=data[:5000]\n",
    "\n",
    "if len(str(data['Problem Statement']).split(\".\",1))>1:\n",
    "  data['Problem Statement']=data['Problem Statement'].str.split(\".\",1).str[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Problem Statement</th>\n",
       "      <th>Solution</th>\n",
       "      <th>tags</th>\n",
       "      <th>prob_sol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Read problems statements in  Mandarin Chinese...</td>\n",
       "      <td>\\n    #include &lt;cstring&gt;\\n    #include &lt;string...</td>\n",
       "      <td>['game']</td>\n",
       "      <td>Read problems statements in  Mandarin Chinese...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Read problems statements in  Mandarin Chinese...</td>\n",
       "      <td>\\n    #include &lt;cstring&gt;\\n    #include &lt;string...</td>\n",
       "      <td>['game']</td>\n",
       "      <td>Read problems statements in  Mandarin Chinese...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Read problems statements in  Mandarin Chinese...</td>\n",
       "      <td>\\n    #include &lt;iostream&gt;\\n    #include &lt;vecto...</td>\n",
       "      <td>['game']</td>\n",
       "      <td>Read problems statements in  Mandarin Chinese...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Read problems statements in  Mandarin Chinese...</td>\n",
       "      <td>\\n    #include &lt;bits/stdc++.h&gt;  \\n    using na...</td>\n",
       "      <td>['game']</td>\n",
       "      <td>Read problems statements in  Mandarin Chinese...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Read problems statements in  Mandarin Chinese...</td>\n",
       "      <td>\\n    /***************************************...</td>\n",
       "      <td>['game']</td>\n",
       "      <td>Read problems statements in  Mandarin Chinese...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Problem Statement  \\\n",
       "0   Read problems statements in  Mandarin Chinese...   \n",
       "1   Read problems statements in  Mandarin Chinese...   \n",
       "2   Read problems statements in  Mandarin Chinese...   \n",
       "3   Read problems statements in  Mandarin Chinese...   \n",
       "4   Read problems statements in  Mandarin Chinese...   \n",
       "\n",
       "                                            Solution      tags  \\\n",
       "0  \\n    #include <cstring>\\n    #include <string...  ['game']   \n",
       "1  \\n    #include <cstring>\\n    #include <string...  ['game']   \n",
       "2  \\n    #include <iostream>\\n    #include <vecto...  ['game']   \n",
       "3  \\n    #include <bits/stdc++.h>  \\n    using na...  ['game']   \n",
       "4  \\n    /***************************************...  ['game']   \n",
       "\n",
       "                                            prob_sol  \n",
       "0   Read problems statements in  Mandarin Chinese...  \n",
       "1   Read problems statements in  Mandarin Chinese...  \n",
       "2   Read problems statements in  Mandarin Chinese...  \n",
       "3   Read problems statements in  Mandarin Chinese...  \n",
       "4   Read problems statements in  Mandarin Chinese...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['prob_sol'] = data['Problem Statement'] +' '+ data['Solution']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/sukku/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "data.head()\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "data['prob_sol'].apply(lambda x: [item for item in x if item not in stop])\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_statement(statement):\n",
    "#     x = re.sub('-', ' ', x)\n",
    "    statement = re.sub('$', ' ', statement)\n",
    "    statement = re.sub('[^A-Za-z]+', ' ', statement)\n",
    "    statement = re.sub('[,|.|?|\\n]|\\t', '', statement)\n",
    "    statement = re.sub('n\\'t', ' ', statement)\n",
    "    statement = re.sub('submission|submissions|Submission|submission|th ', '', statement)\n",
    "    statement = re.sub('one|two|given|need', '', statement)\n",
    "    \n",
    "    return statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tags(tags):\n",
    "    \n",
    "    tags = clean_statement(tags).strip()\n",
    "    tags = list(re.split(' ',tags))\n",
    "    return tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_tags(tags):\n",
    "    \n",
    "    tags_list = []\n",
    "    tags_set = set(tags_list)\n",
    "    \n",
    "    for row in tags:\n",
    "        tags_set = tags_set.union(set(row))\n",
    "        \n",
    "    tags_list = list(tags_set)\n",
    "    \n",
    "    return tags_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dijkstra', 'heap', 'regex', 'gcd', 'pattern', 'simulation', 'suffix', 'pointers', 'kruskal', 'game', 'constructive', 'map', 'combinatorics', 'geometry', 'trees', 'series', 'set', 'dp', 'segment', 'memoization', 'theory', 'interactive', 'fenwick', 'bitwise', 'enumeration', 'matching', 'greedy', 'graphs', 'knapsack', 'number', 'multiset', 'advanced', 'recurrence', 'disjoint', 'hashing', 'hard', 'array', 'bfs', 'recursion', 'basic', 'digraph', 'permutation', 'backtracking', 'sieve', 'fibonacci', 'sets', 'bitmasking', 'combinatorial', 'divide', 'algebra', 'algorithm', 'expo', 'dfs', 'implementation', 'inversions', 'tree', 'fft', 'prime', 'euler', 'tries', 'bipartite', 'probability', 'counting', 'matrix', 'strings', 'maxflow', 'bruteforce', 'adhoc', 'graph', 'parsing', 'binarysearch', 'binary', 'search', 'sorting', 'stack', 'deque', 'dynamic', 'maths']\n"
     ]
    }
   ],
   "source": [
    "# import copy\n",
    "\n",
    "# X = copy.deepcopy(data[\"prob_sol\"])\n",
    "X = data[\"prob_sol\"]\n",
    "Y = [clean_tags(x) for x in data[\"tags\"]]\n",
    "distinct_tags = get_unique_tags(Y)\n",
    "\n",
    "print(distinct_tags)\n",
    "\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "Y = mlb.fit_transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_validation, Y_train, Y_validation = train_test_split(X, Y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('countvectorizer',\n",
       "                 CountVectorizer(analyzer='word', binary=True,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=False, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 3), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, voc...\n",
       "                ('tfidftransformer',\n",
       "                 TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=True,\n",
       "                                  use_idf=True)),\n",
       "                ('onevsrestclassifier',\n",
       "                 OneVsRestClassifier(estimator=LinearSVC(C=1, class_weight=None,\n",
       "                                                         dual=True,\n",
       "                                                         fit_intercept=True,\n",
       "                                                         intercept_scaling=1,\n",
       "                                                         loss='squared_hinge',\n",
       "                                                         max_iter=1000,\n",
       "                                                         multi_class='ovr',\n",
       "                                                         penalty='l2',\n",
       "                                                         random_state=0, tol=1,\n",
       "                                                         verbose=0),\n",
       "                                     n_jobs=None))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = make_pipeline(\n",
    "    CountVectorizer(ngram_range = (1,3),binary = True,lowercase=False),\n",
    "    TfidfTransformer(norm = 'l2',sublinear_tf = True),\n",
    "    OneVsRestClassifier(LinearSVC(penalty=\"l2\",loss=\"squared_hinge\",tol=1,random_state=0,max_iter=1000,C = 1)))\n",
    "\n",
    "classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores( _X , _Y ):\n",
    "    predicted = classifier.predict(_X)\n",
    "    _Y[int(_Y.shape[0]/2),:] =  1\n",
    "    y_labels_predicted = mlb.inverse_transform(predicted)\n",
    "    y_labels_actual = mlb.inverse_transform(_Y)\n",
    "    \n",
    "    \n",
    "    print(\"hamming_loss: \",hamming_loss(_Y,predicted))\n",
    "    print(\"recall_score: \",recall_score(_Y,predicted,average = 'weighted'))\n",
    "    print(\"precision_score: \",precision_score(_Y,predicted,average = 'weighted'))\n",
    "    print(\"f1_score: \",f1_score(_Y,predicted,average = 'weighted'))\n",
    "    print(\"roc_auc_score: \",roc_auc_score(_Y,predicted,average = 'weighted'))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores for Training data\n",
      "hamming_loss:  3.39503815174123e-05\n",
      "recall_score:  0.998042647262009\n",
      "precision_score:  0.9999311615039154\n",
      "f1_score:  0.9989648595977911\n",
      "roc_auc_score:  0.9990207283427975\n",
      "\n",
      "Scores for Validation data\n",
      "hamming_loss:  0.00013579743960100244\n",
      "recall_score:  0.9921418128654971\n",
      "precision_score:  0.9996356451023393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sukku/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score:  0.9956971480394666\n",
      "roc_auc_score:  0.9960691235748799\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#For Train Data\n",
    "print(\"Scores for Training data\")\n",
    "get_scores( X_train, Y_train )\n",
    "print(\"Scores for Validation data\")\n",
    "get_scores( X_validation, Y_validation )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
