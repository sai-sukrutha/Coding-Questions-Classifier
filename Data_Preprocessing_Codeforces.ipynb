{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-20T20:25:14.748806Z",
     "start_time": "2019-04-20T20:25:14.721333Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ssl\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import re\n",
    "import random\n",
    "from pprint import pprint\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler,SMOTE, ADASYN, SMOTENC, SVMSMOTE\n",
    "from imblearn.pipeline import make_pipeline\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "\n",
    "from sklearn.metrics import hamming_loss, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "import wordcloud\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_curve\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import LinearSVC, NuSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "\n",
    "import scikitplot as skplt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras import optimizers\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.metrics import binary_accuracy\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from scipy.special import softmax\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-20T20:25:15.759476Z",
     "start_time": "2019-04-20T20:25:15.741750Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_statement(statement):\n",
    "    statement = re.sub('$', ' ', statement)\n",
    "    statement = re.sub('[^A-Za-z]+', ' ', statement)\n",
    "    statement = re.sub('[,|.|?|\\n]|\\t', '', statement)\n",
    "    statement = re.sub('n\\'t', ' ', statement)\n",
    "    statement = re.sub('submission|submissions|Submission|submission|th ', '', statement)\n",
    "    statement = re.sub('one|two|given|need', '', statement)\n",
    "    \n",
    "    return statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-20T20:25:16.518006Z",
     "start_time": "2019-04-20T20:25:16.498625Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def process_problem_statement(q_statement):\n",
    "    \n",
    "    q_statement = clean_statement(q_statement)\n",
    "    \n",
    "    tokens = word_tokenize(q_statement)\n",
    "    \n",
    "    stoplist = set(stopwords.words('english'))\n",
    "    \n",
    "    word_list = [i for i in q_statement.lower().split() if i not in stoplist]\n",
    "    \n",
    "    ps = PorterStemmer()\n",
    "    \n",
    "    q_statement = ' '.join(word_list)\n",
    "    \n",
    "    return q_statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-20T20:25:17.255743Z",
     "start_time": "2019-04-20T20:25:17.236264Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def process_problem_solution(solution):\n",
    "    tokens = word_tokenize(solution)\n",
    "    stoplist = set(stopwords.words('english'))\n",
    "    word_list = [i for i in solution.lower().split() if i not in stoplist]\n",
    "    solution = ' '.join(word_list)\n",
    "    return solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-20T20:25:31.251095Z",
     "start_time": "2019-04-20T20:25:31.242250Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def process_time_taken(time_col):\n",
    "    return time_col.split()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-20T20:25:29.387766Z",
     "start_time": "2019-04-20T20:25:29.374956Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_tags(all_tags_list,tag_col):\n",
    "    tags_present = list(re.split(',',tag_col))\n",
    "    return tags_present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-20T20:25:26.121122Z",
     "start_time": "2019-04-20T20:25:26.104033Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def get_all_distinct_tags(tags_col):\n",
    "    tags_list = []\n",
    "    t_sets = set(tags_list)\n",
    "    for row in tags_col:\n",
    "        t_list = re.split(',',row)\n",
    "        t_sets = t_sets.union(set(t_list))\n",
    "    tags_list = list(t_sets)\n",
    "    stoplist = set(stopwords.words('english'))\n",
    "    word_list = [i for i in tags_list if i not in stoplist]\n",
    "    return tags_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-20T20:25:28.025627Z",
     "start_time": "2019-04-20T20:25:28.014653Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# tag list obtained from the dataset\n",
    "tags_list = ['dsu', 'trees', 'chinese remainder theorem', 'sortings', 'games', 'implementation', 'bitmasks',\n",
    "              '*special', 'hashing', 'geometry', 'two pointers', 'combinatorics', 'flows', 'strings',\n",
    "              'probabilities', 'data structures', 'ternary search', 'greedy', 'math', 'matrices',\n",
    "              'divide and conquer', 'dfs and similar', 'constructive algorithms', 'brute force', 'dp',\n",
    "              '2-sat', 'graph matchings', 'binary search', 'number theory', 'graphs', 'fft', 'shortest paths',\n",
    "              'schedules', 'meet-in-the-middle', 'string suffix structures', 'expression parsing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-20T21:06:31.606243Z",
     "start_time": "2019-04-20T21:06:31.599409Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_class_distribution(Y,classes):  \n",
    "    count_list = [0]*Y.shape[1]\n",
    "    for index in range(Y.shape[1]):\n",
    "        count_list[index] = np.sum(Y[:,index])/Y.shape[0]\n",
    "    plt.figure(figsize=(10, 10), dpi=100)\n",
    "    plt.barh(classes,count_list, align='center', alpha=0.5)\n",
    "    plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-20T21:03:44.133703Z",
     "start_time": "2019-04-20T21:03:44.089889Z"
    }
   },
   "outputs": [],
   "source": [
    "def data_preprocessing():\n",
    "    df = pd.read_csv(\"./codeforces_question_v5.csv\")\n",
    "    df = df.drop(['id','name','author'],axis = 1)\n",
    "    df = df[df.solution != \"no code found\"]\n",
    "    df = df.dropna()\n",
    "   \n",
    "    global distinct_tags\n",
    "    \n",
    "    distinct_tags = get_all_distinct_tags(df[\"tags\"])\n",
    "    \n",
    "    df[\"problem statement\"] = [process_problem_statement(x) for x in df[\"problem statement\"]]\n",
    "    df[\"solution\"] = [process_problem_solution(x) for x in df[\"solution\"]]\n",
    "    df[\"time_taken\"] = [process_time_taken(x) for x in df[\"time_taken\"]]\n",
    "    \n",
    "    X = copy.deepcopy(df[\"solution\"]+df[\"time_taken\"])\n",
    "    Y = [process_tags(distinct_tags,x) for x in df[\"tags\"]]\n",
    "\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    Y = mlb.fit_transform(Y)\n",
    "    print(\"Tags: \")\n",
    "    print(mlb.classes_)\n",
    "    print()\n",
    "    plot_class_distribution(Y,mlb.classes_)    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-20T21:10:33.137336Z",
     "start_time": "2019-04-20T21:09:15.866992Z"
    },
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "global distinct_tags\n",
    "X,Y = data_preprocessing()\n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
